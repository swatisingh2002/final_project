from flask import Flask, render_template, request
from transformers import GPT2Tokenizer, GPT2LMHeadModel
import torch
import nltk
from nltk.probability import FreqDist
from collections import Counter
from nltk.corpus import stopwords
import string
import plotly.express as px
import plotly.io as pio
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
import os
import requests
import json

# Ensure necessary NLTK data packages are downloaded
nltk.download('punkt')
nltk.download('stopwords')

# Load GPT-2 tokenizer and model
tokenizer = GPT2Tokenizer.from_pretrained('gpt2')
model = GPT2LMHeadModel.from_pretrained('gpt2')

app = Flask(__name__)

# Function to read a file
def read_file(file):
    return file.read().decode('utf-8')

# Function to vectorize texts
def vectorize(texts):
    vectorizer = TfidfVectorizer()
    tfidf_matrix = vectorizer.fit_transform(texts)
    return tfidf_matrix.toarray()

# Function to calculate similarity between two documents
def similarity(doc1, doc2):
    return cosine_similarity([doc1], [doc2])[0][0]

# Route for the main index page
@app.route('/')
def index():
    return render_template('index.html')

# Route for uploading and checking files for plagiarism
@app.route('/upload', methods=['GET', 'POST'])
def upload_files():
    result = None
    if request.method == 'POST':
        if 'file1' not in request.files or 'file2' not in request.files:
            return "Please upload both files", 400

        file1 = request.files['file1']
        file2 = request.files['file2']

        if file1.filename == '' or file2.filename == '':
            return "Please select both files", 400

        text1 = read_file(file1)
        text2 = read_file(file2)
        student_notes = [text1, text2]

        vectors = vectorize(student_notes)
        sim_score = similarity(vectors[0], vectors[1])
        sim_score = round(sim_score, 2)

        student_a = os.path.splitext(file1.filename)[0]
        student_b = os.path.splitext(file2.filename)[0]
        result = f"{student_a} is {sim_score * 100}% similar to {student_b}"

    return render_template('upload.html', result=result)

# Route for checking text for AI generation
@app.route('/check', methods=['GET', 'POST'])
def check_text():
    result = None
    if request.method == 'POST':
        text_to_check = request.form['text_to_check']

        # Your plagiarism check code here

    return render_template('check.html', result=result)

# Route for checking text for AI generation (GPT-2 analysis)
@app.route('/ai-check', methods=['GET', 'POST'])
def ai_check():
    if request.method == 'POST':
        text_area = request.form['text_area']
        perplexity = calculate_perplexity(text_area)
        burstiness_score = calculate_burstiness(text_area)
        plot_html = plot_top_repeated_words(text_area)

        result_message = "Text Analysis Result: Likely not generated by AI"
        if perplexity is not None and burstiness_score is not None and perplexity > 50 or burstiness_score < 2.5:
            result_message = "Text Analysis Result: AI generated content"

        return render_template('ai_result.html', text_area=text_area, perplexity=perplexity, 
                               burstiness_score=burstiness_score, result_message=result_message, plot_html=plot_html)

    return render_template('ai_check.html')

def calculate_perplexity(text):
    # Ensure text is not empty
    if not text.strip():
        return None

    # Tokenize the text
    encoded_input = tokenizer.encode(text, add_special_tokens=True, return_tensors='pt')
    
    # Check token length
    if len(encoded_input[0]) > tokenizer.model_max_length:
        return None

    # Move input to appropriate device
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    encoded_input = encoded_input.to(device)

    # Move model to device
    model.to(device)

    # Calculate perplexity
    with torch.no_grad():
        outputs = model(encoded_input, labels=encoded_input)
        loss = outputs.loss
        perplexity = torch.exp(loss)

    return perplexity.item() if perplexity else None

def calculate_burstiness(text):
    tokens = nltk.word_tokenize(text.lower())
    word_freq = FreqDist(tokens)
    repeated_count = sum(count > 1 for count in word_freq.values())
    burstiness_score = repeated_count / len(word_freq)
    return burstiness_score

def plot_top_repeated_words(text):
    tokens = text.split()
    stop_words = set(stopwords.words('english'))
    tokens = [token.lower() for token in tokens if token.lower() not in stop_words and token.lower() not in string.punctuation]
    word_counts = Counter(tokens)
    top_words = word_counts.most_common(15)
    words = [word for word, count in top_words]
    counts = [count for word, count in top_words]
    fig = px.bar(x=words, y=counts, labels={'x': 'Words', 'y': 'Counts'}, title='Top 15 Most Repeated Words')
    return pio.to_html(fig, full_html=False)

if __name__ == "__main__":
    app.run(debug=True, port=5555)
